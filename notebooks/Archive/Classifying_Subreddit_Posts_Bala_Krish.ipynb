{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Subreddit Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview <br>\n",
    "\n",
    "**Goal:** The goal is to build a model that can classify reddit posts into the subreddit they belong to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology \n",
    "\n",
    "To do this, I will build and compare two classifiers: **Logistic Regression** and **RandomForest**. Each classifier will rely on natural language processing (NLP) on the text within each post to better understand the characteristics (and ideally context) of the post. By doing so, the classifier will learn which post belongs in which subreddit. \n",
    "\n",
    "Here is an overview of the steps taken to build each classifier: <br>\n",
    "\n",
    "Steps common to both classifiers: \n",
    "- Pull posts from subreddits being examined using Reddit's API\n",
    "- Clean gathered data to extract post content (text), and any other potential identifying characteristics within each post. <br>\n",
    "- NLP: <br>\n",
    "    - Tokenize & lemmatize/stem data\n",
    "    - Vectorize data (CountVectorizer, HasingVectorizer, TF-IDF)\n",
    "- Modelling (Logisitic Regression, Random Forest)\n",
    "- Evaluate Model (initial)\n",
    "- Changes + Hyperparameter tuning: GridSearch, others? <br>\n",
    "- Evaluate Model (final)\n",
    "\n",
    "\n",
    "Logistic Regression: <br>\n",
    "\n",
    "Random Forest: <br> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"} # For dark themed j-notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling data from r/showerthoughts\n",
    "\n",
    "url = 'https://www.reddit.com/r/showerthoughts.json'\n",
    "agent = {'User-agent': 'redditter04'}\n",
    "res = requests.get(url, headers=agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shower_json = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'kind']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine json file\n",
    "sorted(shower_json.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['after', 'before', 'children', 'dist', 'modhash']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(shower_json['data'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shower_json['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 'children' key stores each post. Note that the first post is a \"welcome\" post - this will\n",
    "# be excluded from the analysis.\n",
    "\n",
    "len(shower_json['data']['children'])\n",
    "# There are 25 posts (exluding welcome post) per request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(shower_json['data']['children'][0]['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling posts from: science/ ...\n",
      "\n",
      "Pulling filter: rising ...\n",
      "\n",
      "Requests made: 0\n",
      "Requests made: 10\n",
      "Requests made: 20\n",
      "Requests made: 30\n",
      "Requests made: 40\n",
      "Requests made: 50\n",
      "Requests made: 60\n",
      "Requests made: 70\n",
      "Requests made: 80\n",
      "Requests made: 90\n",
      "\n",
      "Num of Posts Collected (last subreddit): 200\n",
      "Time Elapsed: 0:00:19.205557\n",
      "Code ended at: 2018-12-17-01PM:51\n"
     ]
    }
   ],
   "source": [
    "# Pulling posts from subreddits\n",
    "\n",
    "## Set timer\n",
    "t0 = time.time()\n",
    "\n",
    "# Define parameters used in for-loop below\n",
    "# Subreddits: 'technology/', 'fitness/', 'sports/', 'showerthoughts/', 'mildlyinteresting/'\n",
    "# 'controversial', 'top', 'rising'\n",
    "subreddits = ['science/']\n",
    "filters = ['new'] # The most number of subreddit posts \n",
    "for subreddit in subreddits:\n",
    "    posts = []\n",
    "    print('Pulling posts from:', subreddit, '...')\n",
    "    print()\n",
    "    for filter in filters: \n",
    "        print('Pulling filter:', filter, '...')\n",
    "        print()\n",
    "        url = 'https://www.reddit.com/r/' + subreddit + filter + '.json'\n",
    "        after = None\n",
    "        agent = {'User-agent': 'red_bk'}\n",
    "        num_requests = 100 # Number of times to request posts from reddit's API\n",
    "        for i in range(num_requests):\n",
    "            if i % 10 == 0:\n",
    "                print('Requests made:', i)\n",
    "            if after == None:\n",
    "                params = {} # this dict represents the unique tag that tells us the last post pulled\n",
    "            else:\n",
    "                params = {'after': after}\n",
    "            res = requests.get(url, headers=agent, params=params)\n",
    "            if res.status_code == 200:\n",
    "                the_json = res.json()\n",
    "                posts.extend(the_json['data']['children'])\n",
    "                after = the_json['data']['after']\n",
    "                if i % 5 == 0:\n",
    "                    agent['User-agent'] = 'red_bk' + str(i)\n",
    "            else:\n",
    "                print('Error:', status_code)\n",
    "                break\n",
    "        # Convert subreddit list of dictionaries to posts\n",
    "    df_rising = pd.DataFrame(posts)\n",
    "#     df.to_csv('./data/' + subreddit[:-1] + '_' + time.strftime('%Y-%m-%d-%I%p'), index=False)\n",
    "    time.sleep(1)\n",
    "\n",
    "time_elapsed_secs = time.time() - t0 # time elapsed in seconds\n",
    "print()\n",
    "print('Num of Posts Collected (last subreddit):', len(posts))\n",
    "print('Time Elapsed:', datetime.timedelta(seconds=time_elapsed_secs))\n",
    "print('Code ended at:', time.strftime('%Y-%m-%d-%I%p:%M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2437"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shower_df = pd.read_csv('./data/showerthoughts2018-12-16-04PM')\n",
    "science_df = pd.read_csv('./data/science_2018-12-17-01PM')\n",
    "# tech_df = pd.read_csv('./data/technology2018-12-17-12PM')\n",
    "# fit_df = pd.read_csv('./data/fitness2018-12-16-04PM')\n",
    "# sports_df = pd.read_csv('./data/sports2018-12-16-04PM')\n",
    "# mild_df = pd.read_csv('./data/mildlyinteresting2018-12-16-04PM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = [science_df, df_top, df_new, df_cont, df_rising, df_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionaries stored as strings back to dictionaries\n",
    "# for df in list_of_dfs:\n",
    "science_df['data'] = science_df['data'].map(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check type of dict entry\n",
    "# type(science_df['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_df.drop(columns='post_name', inplace=True)\n",
    "df_top.drop(columns='post_name', inplace=True)\n",
    "df_new.drop(columns='post_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "science Num of Unique Posts: 704\n",
      "science Num of Unique Posts: 33\n",
      "science Num of Unique Posts: 868\n",
      "science Num of Unique Posts: 33\n",
      "science Num of Unique Posts: 2\n",
      "science Num of Unique Posts: 868\n"
     ]
    }
   ],
   "source": [
    "# Num of unique posts in each subreddit (using 'name' for each post as an identifier)\n",
    "\n",
    "for df in list_of_dfs:\n",
    "#     sr_name = df['data'][0]['subreddit']\n",
    "    df['post_name'] = df['data'].map(lambda x: x['name'])\n",
    "    print(sr_name, 'Num of Unique Posts:', len(set(df['post_name'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([science_df, df_top, df_new, df_rising, df_cont])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'scienc...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'scienc...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'scienc...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'scienc...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'scienc...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data kind\n",
       "0  {'approved_at_utc': None, 'subreddit': 'scienc...   t3\n",
       "1  {'approved_at_utc': None, 'subreddit': 'scienc...   t3\n",
       "2  {'approved_at_utc': None, 'subreddit': 'scienc...   t3\n",
       "3  {'approved_at_utc': None, 'subreddit': 'scienc...   t3\n",
       "4  {'approved_at_utc': None, 'subreddit': 'scienc...   t3"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by cleaning posts from the r/science and r/technology subreddits. These subreddits are relatively similar in terms of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dictionary entries for each post into individual columns \n",
    "\n",
    "# r/science df\n",
    "\n",
    "dict_keys = sorted(eval(science_df['data'][0]).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96    2147\n",
       "94     316\n",
       "92       6\n",
       "97       4\n",
       "99       3\n",
       "90       3\n",
       "Name: data, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of keys (i.e. data fields) for each post\n",
    "science_df['data'].map(lambda x: len(eval(x).keys())).value_counts()\n",
    "\n",
    "# Results show some approx. 12% of posts lack 2 keys (compared to the majority of posts), while \n",
    "# very few have more/less than that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['approved_at_utc', 'approved_by', 'archived', 'author', 'author_flair_background_color', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_template_id', 'author_flair_text', 'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_patreon_flair', 'banned_at_utc', 'banned_by', 'can_gild', 'can_mod_post', 'category', 'clicked', 'content_categories', 'contest_mode', 'created', 'created_utc', 'distinguished', 'domain', 'downs', 'edited', 'gilded', 'gildings', 'hidden', 'hide_score', 'id', 'is_crosspostable', 'is_meta', 'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video', 'likes', 'link_flair_background_color', 'link_flair_css_class', 'link_flair_richtext', 'link_flair_template_id', 'link_flair_text', 'link_flair_text_color', 'link_flair_type', 'locked', 'media', 'media_embed', 'media_only', 'mod_note', 'mod_reason_by', 'mod_reason_title', 'mod_reports', 'name', 'no_follow', 'num_comments', 'num_crossposts', 'num_reports', 'over_18', 'parent_whitelist_status', 'permalink', 'pinned', 'post_hint', 'preview', 'pwls', 'quarantine', 'removal_reason', 'report_reasons', 'saved', 'score', 'secure_media', 'secure_media_embed', 'selftext', 'selftext_html', 'send_replies', 'spoiler', 'stickied', 'subreddit', 'subreddit_id', 'subreddit_name_prefixed', 'subreddit_subscribers', 'subreddit_type', 'suggested_sort', 'thumbnail', 'thumbnail_height', 'thumbnail_width', 'title', 'ups', 'url', 'user_reports', 'view_count', 'visited', 'whitelist_status', 'wls']\n"
     ]
    }
   ],
   "source": [
    "# List of data fields within each post\n",
    "print(dict_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the data fields above shows that many of them contain data for admin/formatting purposes, as opposed to information on the content of the post (e.g. \"author_flair_background_color\", \"is_robot_indexable\", etc.) that might allude to which subreddit it belongs to. Thus, I will select a subset of these data fields to examine in further detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected data fields\n",
    "\n",
    "post_fields = ['approved_by', 'author', 'category', 'content_categories', 'created', 'domain', \n",
    "              'likes', 'media', 'name', 'num_comments', 'num_crossposts', 'num_reports','selftext',\n",
    "               'subreddit', 'title', 'wls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in post_fields:\n",
    "    science_df[field] = science_df['data'].map(lambda x: eval(x)[field])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine some columns in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>kind</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>content_categories</th>\n",
       "      <th>created</th>\n",
       "      <th>domain</th>\n",
       "      <th>likes</th>\n",
       "      <th>media</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>num_reports</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>wls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'scienc...</td>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>Wagamaga</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.545026e+09</td>\n",
       "      <td>irishcentral.com</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_a6tbhu</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>science</td>\n",
       "      <td>Healthy levels of Vitamin D are linked to a 75...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'scienc...</td>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>mvea</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.544988e+09</td>\n",
       "      <td>news.psu.edu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_a6ocrh</td>\n",
       "      <td>916</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>science</td>\n",
       "      <td>People who met and became acquainted with at l...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'scienc...</td>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>avogadros_number</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.545021e+09</td>\n",
       "      <td>e360.yale.edu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_a6smhu</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>science</td>\n",
       "      <td>Nearly 70% of infrastructure in the Arctic - i...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'scienc...</td>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>Wagamaga</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.545017e+09</td>\n",
       "      <td>eastbaytimes.com</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_a6rxe0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>science</td>\n",
       "      <td>Sierra Nevada snow pack on track to shrink 79 ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'scienc...</td>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>mvea</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.545023e+09</td>\n",
       "      <td>psypost.org</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_a6st6e</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>science</td>\n",
       "      <td>Men tend to perceive both polygyny — in which ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'scienc...</td>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>p1percub</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.545003e+09</td>\n",
       "      <td>self.science</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_a6pvdj</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>#Thank you, readers of r/science, for helping ...</td>\n",
       "      <td>science</td>\n",
       "      <td>r/science has reached 20M subscribers! To cele...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'scienc...</td>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>mvea</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.544966e+09</td>\n",
       "      <td>psypost.org</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_a6mi7e</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>science</td>\n",
       "      <td>The development of a kind, caring, and warm at...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'scienc...</td>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>mvea</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.544936e+09</td>\n",
       "      <td>psypost.org</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_a6ipw7</td>\n",
       "      <td>2235</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>science</td>\n",
       "      <td>Being in a committed relationship, having excl...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'scienc...</td>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>The_Old_Wise_One</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.545002e+09</td>\n",
       "      <td>jasoncollins.blog</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_a6pp34</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>science</td>\n",
       "      <td>Multi-lab, high-powered replication of widespr...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'scienc...</td>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>jq1984_is_me</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.544925e+09</td>\n",
       "      <td>liebertpub.com</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_a6h7fc</td>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>science</td>\n",
       "      <td>Breastfeeding Greater Than 6 Months Is Associa...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data kind approved_by  \\\n",
       "0  {'approved_at_utc': None, 'subreddit': 'scienc...   t3        None   \n",
       "1  {'approved_at_utc': None, 'subreddit': 'scienc...   t3        None   \n",
       "2  {'approved_at_utc': None, 'subreddit': 'scienc...   t3        None   \n",
       "3  {'approved_at_utc': None, 'subreddit': 'scienc...   t3        None   \n",
       "4  {'approved_at_utc': None, 'subreddit': 'scienc...   t3        None   \n",
       "5  {'approved_at_utc': None, 'subreddit': 'scienc...   t3        None   \n",
       "6  {'approved_at_utc': None, 'subreddit': 'scienc...   t3        None   \n",
       "7  {'approved_at_utc': None, 'subreddit': 'scienc...   t3        None   \n",
       "8  {'approved_at_utc': None, 'subreddit': 'scienc...   t3        None   \n",
       "9  {'approved_at_utc': None, 'subreddit': 'scienc...   t3        None   \n",
       "\n",
       "             author category content_categories       created  \\\n",
       "0          Wagamaga     None               None  1.545026e+09   \n",
       "1              mvea     None               None  1.544988e+09   \n",
       "2  avogadros_number     None               None  1.545021e+09   \n",
       "3          Wagamaga     None               None  1.545017e+09   \n",
       "4              mvea     None               None  1.545023e+09   \n",
       "5          p1percub     None               None  1.545003e+09   \n",
       "6              mvea     None               None  1.544966e+09   \n",
       "7              mvea     None               None  1.544936e+09   \n",
       "8  The_Old_Wise_One     None               None  1.545002e+09   \n",
       "9      jq1984_is_me     None               None  1.544925e+09   \n",
       "\n",
       "              domain likes media       name  num_comments  num_crossposts  \\\n",
       "0   irishcentral.com  None  None  t3_a6tbhu            85               1   \n",
       "1       news.psu.edu  None  None  t3_a6ocrh           916               3   \n",
       "2      e360.yale.edu  None  None  t3_a6smhu            24               0   \n",
       "3   eastbaytimes.com  None  None  t3_a6rxe0            11               4   \n",
       "4        psypost.org  None  None  t3_a6st6e            24               1   \n",
       "5       self.science  None  None  t3_a6pvdj            70               0   \n",
       "6        psypost.org  None  None  t3_a6mi7e            35               1   \n",
       "7        psypost.org  None  None  t3_a6ipw7          2235               7   \n",
       "8  jasoncollins.blog  None  None  t3_a6pp34            23               1   \n",
       "9     liebertpub.com  None  None  t3_a6h7fc           337               1   \n",
       "\n",
       "  num_reports                                           selftext subreddit  \\\n",
       "0        None                                                      science   \n",
       "1        None                                                      science   \n",
       "2        None                                                      science   \n",
       "3        None                                                      science   \n",
       "4        None                                                      science   \n",
       "5        None  #Thank you, readers of r/science, for helping ...   science   \n",
       "6        None                                                      science   \n",
       "7        None                                                      science   \n",
       "8        None                                                      science   \n",
       "9        None                                                      science   \n",
       "\n",
       "                                               title  wls  \n",
       "0  Healthy levels of Vitamin D are linked to a 75...    6  \n",
       "1  People who met and became acquainted with at l...    6  \n",
       "2  Nearly 70% of infrastructure in the Arctic - i...    6  \n",
       "3  Sierra Nevada snow pack on track to shrink 79 ...    6  \n",
       "4  Men tend to perceive both polygyny — in which ...    6  \n",
       "5  r/science has reached 20M subscribers! To cele...    6  \n",
       "6  The development of a kind, caring, and warm at...    6  \n",
       "7  Being in a committed relationship, having excl...    6  \n",
       "8  Multi-lab, high-powered replication of widespr...    6  \n",
       "9  Breastfeeding Greater Than 6 Months Is Associa...    6  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "science_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approved_by 2479\n",
      "author 0\n",
      "category 2479\n",
      "content_categories 2479\n",
      "created 0\n",
      "domain 0\n",
      "likes 2479\n",
      "media 2479\n",
      "name 0\n",
      "num_comments 0\n",
      "num_crossposts 0\n",
      "num_reports 2479\n",
      "selftext 0\n",
      "subreddit 0\n",
      "title 0\n",
      "wls 0\n"
     ]
    }
   ],
   "source": [
    "# Check for null values within columns in df\n",
    "for col in science_df.columns[2:]:\n",
    "    print(col, science_df[col].isnull().sum())\n",
    "    \n",
    "# Columns with null values will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null columns and original data columns\n",
    "science_df.drop(columns=['approved_by', 'category', 'content_categories', 'likes', 'media',\n",
    "                         'num_reports', 'data', 'kind'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most values in column 'selftext' appear to be empty strings, and the cells with values don't \n",
    "# appear to be good candidates for feature selection. Thus, let's remove 'selftext' as well.\n",
    "science_df['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_df.drop(columns='selftext', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'created', 'domain', 'name', 'num_comments', 'num_crossposts',\n",
       "       'subreddit', 'title', 'wls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below is the draft list of candidates for feature selection for the r/science subreddit.\n",
    "features_list = science_df.columns\n",
    "features_list.drop(labels='subreddit')\n",
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target value is the column with the subreddit's name\n",
    "target_field = 'subreddit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created</th>\n",
       "      <th>domain</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>wls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wagamaga</td>\n",
       "      <td>1.545026e+09</td>\n",
       "      <td>irishcentral.com</td>\n",
       "      <td>t3_a6tbhu</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>science</td>\n",
       "      <td>Healthy levels of Vitamin D are linked to a 75...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mvea</td>\n",
       "      <td>1.544988e+09</td>\n",
       "      <td>news.psu.edu</td>\n",
       "      <td>t3_a6ocrh</td>\n",
       "      <td>916</td>\n",
       "      <td>3</td>\n",
       "      <td>science</td>\n",
       "      <td>People who met and became acquainted with at l...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avogadros_number</td>\n",
       "      <td>1.545021e+09</td>\n",
       "      <td>e360.yale.edu</td>\n",
       "      <td>t3_a6smhu</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>science</td>\n",
       "      <td>Nearly 70% of infrastructure in the Arctic - i...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wagamaga</td>\n",
       "      <td>1.545017e+09</td>\n",
       "      <td>eastbaytimes.com</td>\n",
       "      <td>t3_a6rxe0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>science</td>\n",
       "      <td>Sierra Nevada snow pack on track to shrink 79 ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mvea</td>\n",
       "      <td>1.545023e+09</td>\n",
       "      <td>psypost.org</td>\n",
       "      <td>t3_a6st6e</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>science</td>\n",
       "      <td>Men tend to perceive both polygyny — in which ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p1percub</td>\n",
       "      <td>1.545003e+09</td>\n",
       "      <td>self.science</td>\n",
       "      <td>t3_a6pvdj</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>science</td>\n",
       "      <td>r/science has reached 20M subscribers! To cele...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mvea</td>\n",
       "      <td>1.544966e+09</td>\n",
       "      <td>psypost.org</td>\n",
       "      <td>t3_a6mi7e</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>science</td>\n",
       "      <td>The development of a kind, caring, and warm at...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mvea</td>\n",
       "      <td>1.544936e+09</td>\n",
       "      <td>psypost.org</td>\n",
       "      <td>t3_a6ipw7</td>\n",
       "      <td>2235</td>\n",
       "      <td>7</td>\n",
       "      <td>science</td>\n",
       "      <td>Being in a committed relationship, having excl...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The_Old_Wise_One</td>\n",
       "      <td>1.545002e+09</td>\n",
       "      <td>jasoncollins.blog</td>\n",
       "      <td>t3_a6pp34</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>science</td>\n",
       "      <td>Multi-lab, high-powered replication of widespr...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jq1984_is_me</td>\n",
       "      <td>1.544925e+09</td>\n",
       "      <td>liebertpub.com</td>\n",
       "      <td>t3_a6h7fc</td>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>science</td>\n",
       "      <td>Breastfeeding Greater Than 6 Months Is Associa...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author       created             domain       name  num_comments  \\\n",
       "0          Wagamaga  1.545026e+09   irishcentral.com  t3_a6tbhu            85   \n",
       "1              mvea  1.544988e+09       news.psu.edu  t3_a6ocrh           916   \n",
       "2  avogadros_number  1.545021e+09      e360.yale.edu  t3_a6smhu            24   \n",
       "3          Wagamaga  1.545017e+09   eastbaytimes.com  t3_a6rxe0            11   \n",
       "4              mvea  1.545023e+09        psypost.org  t3_a6st6e            24   \n",
       "5          p1percub  1.545003e+09       self.science  t3_a6pvdj            70   \n",
       "6              mvea  1.544966e+09        psypost.org  t3_a6mi7e            35   \n",
       "7              mvea  1.544936e+09        psypost.org  t3_a6ipw7          2235   \n",
       "8  The_Old_Wise_One  1.545002e+09  jasoncollins.blog  t3_a6pp34            23   \n",
       "9      jq1984_is_me  1.544925e+09     liebertpub.com  t3_a6h7fc           337   \n",
       "\n",
       "   num_crossposts subreddit  \\\n",
       "0               1   science   \n",
       "1               3   science   \n",
       "2               0   science   \n",
       "3               4   science   \n",
       "4               1   science   \n",
       "5               0   science   \n",
       "6               1   science   \n",
       "7               7   science   \n",
       "8               1   science   \n",
       "9               1   science   \n",
       "\n",
       "                                               title  wls  \n",
       "0  Healthy levels of Vitamin D are linked to a 75...    6  \n",
       "1  People who met and became acquainted with at l...    6  \n",
       "2  Nearly 70% of infrastructure in the Arctic - i...    6  \n",
       "3  Sierra Nevada snow pack on track to shrink 79 ...    6  \n",
       "4  Men tend to perceive both polygyny — in which ...    6  \n",
       "5  r/science has reached 20M subscribers! To cele...    6  \n",
       "6  The development of a kind, caring, and warm at...    6  \n",
       "7  Being in a committed relationship, having excl...    6  \n",
       "8  Multi-lab, high-powered replication of widespr...    6  \n",
       "9  Breastfeeding Greater Than 6 Months Is Associa...    6  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "science_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Along with 'title', 'author' and 'domain' may be potentially good features to help our classifier predict which subreddit a post belongs to._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of posts by subreddit as of June, 2017: https://gist.github.com/anonymous/ef075ee973dd5f883ae17729c147c1de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
